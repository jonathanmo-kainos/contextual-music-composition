from tensorflow.compat.v1.keras.models import load_model
from tensorflow.keras.layers import Input
from tensorflow.keras.models import Sequential
import numpy as np
import enums

def generate_and_save_samples_encoded(samples, name):
    encoder_model = load_model(enums.ENCODER_2000_FILEPATH)
    encoded_samples = []

    print('encoding ' + name + ' samples')
    for i in range(samples.shape[0]):
        midi_matrix = samples[i].reshape(1, 16, 96, 96)
        sample = encoder_model.predict(midi_matrix)
        encoded_samples.append(sample)

    print(len(encoded_samples) + ' samples encoded')
    np.save('../samples/' + name + ' encoded samples.npy', encoded_samples)

def split_autoencoder_trained_model_into_encoder_and_decoder_models(model):
    create_encoder_model_from_trained_autoencoder(model)
    create_decoder_model_from_trained_autoencoder(model)

def create_encoder_model_from_trained_autoencoder(model):
    encoder_model = Sequential()
    for layer in model.layers[:6]:
        encoder_model.add(layer)

    print(encoder_model.summary())
    encoder_model.load_weights(enums.AUTOENCODER_20001_FILEPATH, by_name=True)
    encoder_model.save(enums.ENCODER_2000_FILEPATH)

def create_decoder_model_from_trained_autoencoder(model):
    decoder_model = Sequential()
    decoder_model.add(Input(shape=(120)))
    for layer in model.layers[7:]:
        decoder_model.add(layer)

    print(decoder_model.summary())
    decoder_model.load_weights(enums.AUTOENCODER_20001_FILEPATH, by_name=True)
    decoder_model.save(enums.DECODER_2000_FILEPATH)

model = load_model(enums.AUTOENCODER_2000_FILEPATH)
split_autoencoder_trained_model_into_encoder_and_decoder_models(model)

samples = np.load(enums.ALL_SAMPLES_FILEPATH)
major_samples = np.load(enums.MAJOR_SAMPLES_FILEPATH)
minor_samples = np.load(enums.MINOR_SAMPLES_FILEPATH)

generate_and_save_samples_encoded(samples, 'all')
generate_and_save_samples_encoded(major_samples, 'major')
generate_and_save_samples_encoded(minor_samples, 'minor')